{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The goal of this challenge is to predict future claims for health insurance enrollees. This will help the healthcare insurer adequately set the premiums.\n",
    "The data consists of patient profile including patient age, sex ,chronic conditions and severity of each chronic condition, history of outpatient claims for past few years is also included.\n",
    "The goal is to predict the total claims for the next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:54:05.652223Z",
     "iopub.status.busy": "2024-12-02T23:54:05.651828Z",
     "iopub.status.idle": "2024-12-03T00:07:28.431963Z",
     "shell.execute_reply": "2024-12-03T00:07:28.430849Z",
     "shell.execute_reply.started": "2024-12-02T23:54:05.652173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "# 1. Load the data\n",
    "train_json_path = 'patient_data_train.json'\n",
    "test_json_path = 'patient_data_test.json'\n",
    "train_csv_path = 'train.csv'\n",
    "submission_csv_path = 'sample_submission.csv'\n",
    "\n",
    "# Load JSON files\n",
    "with open(train_json_path, 'r') as f:\n",
    "    train_json_data = json.load(f)\n",
    "\n",
    "with open(test_json_path, 'r') as f:\n",
    "    test_json_data = json.load(f)\n",
    "\n",
    "# Load CSV files\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "submission_csv = pd.read_csv(submission_csv_path)\n",
    "\n",
    "# 2. Preprocess the data and add the severity column\n",
    "def process_json_data(json_data):\n",
    "    processed_data = []\n",
    "    for patient in json_data:\n",
    "        patient_id = patient['PatientID']\n",
    "        sex = 1 if patient['Sex'] == 'M' else 0\n",
    "        age = patient['Age']\n",
    "        conditions = patient['Conditions']\n",
    "\n",
    "        total_severity = sum(conditions.values())\n",
    "\n",
    "        outpatient_costs = patient.get('Out patient costs', {})\n",
    "        avg_cost = {year: outpatient_costs.get(str(year), 0) for year in range(2019, 2024)}\n",
    "        \n",
    "        data_row = {\n",
    "            'PatientID': patient_id,\n",
    "            'Sex': sex,\n",
    "            'Age': age,\n",
    "            'Conditions_AT': conditions.get('AT', 0),\n",
    "            'Conditions_DB': conditions.get('DB', 0),\n",
    "            'Conditions_HT': conditions.get('HT', 0),\n",
    "            'Conditions_HD': conditions.get('HD', 0),\n",
    "            'TotalSeverity': total_severity,\n",
    "            'Outpatient_2019': avg_cost[2019],\n",
    "            'Outpatient_2020': avg_cost[2020],\n",
    "            'Outpatient_2021': avg_cost[2021],\n",
    "            'Outpatient_2022': avg_cost[2022],\n",
    "            'Outpatient_2023': avg_cost[2023]\n",
    "        }\n",
    "        processed_data.append(data_row)\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process both train and test data\n",
    "train_df = process_json_data(train_json_data)\n",
    "test_df = process_json_data(test_json_data)\n",
    "\n",
    "# 3. Merge the train CSV with the processed train JSON data\n",
    "train_merged = pd.merge(train_df, train_csv, on='PatientID')\n",
    "\n",
    "# Drop 'PatientID' column since it's not needed for training\n",
    "train_merged.drop(columns=['PatientID'], inplace=True)\n",
    "\n",
    "# Outlier removal based on TotalClaims using z-score\n",
    "train_merged['zscore'] = zscore(train_merged['TotalClaims'])\n",
    "train_merged = train_merged[train_merged['zscore'].abs() < 3]\n",
    "\n",
    "# 4. Split the Data\n",
    "X = train_merged.drop(columns=['TotalClaims', 'zscore'])\n",
    "y = train_merged['TotalClaims']\n",
    "X_train_important, X_val_important, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Feature Engineering\n",
    "def add_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Adds new features to the dataset for better feature representation.\n",
    "    \"\"\"\n",
    "    if 'Outpatient_2023' in df.columns:\n",
    "        df['Outpatient_2023_log'] = np.log1p(df['Outpatient_2023'])  # Log transformation\n",
    "    \n",
    "    if 'Age' in df.columns:\n",
    "        df['Age_Squared'] = df['Age'] ** 2\n",
    "        df['Age_Cubed'] = df['Age'] ** 3  # Cubic feature\n",
    "    \n",
    "    if 'TotalSeverity' in df.columns:\n",
    "        df['Severity_Squared'] = df['TotalSeverity'] ** 2\n",
    "        df['Severity_Cubed'] = df['TotalSeverity'] ** 3  # Cubic feature\n",
    "    \n",
    "    # Interaction features\n",
    "    df['Age_Severity_Interaction'] = df['Age'] * df['TotalSeverity']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to training, validation, and test sets\n",
    "X_train_important = add_advanced_features(X_train_important)\n",
    "X_val_important = add_advanced_features(X_val_important)\n",
    "test_df = add_advanced_features(test_df)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_important)\n",
    "X_val_scaled = scaler.transform(X_val_important)\n",
    "test_df_scaled = scaler.transform(test_df[X_train_important.columns])\n",
    "\n",
    "# 6. Hyperparameter Tuning with Bayesian Optimization using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)  # Regularization parameter\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', **param)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)],\n",
    "              early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    return mae\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Parameters (XGBoost): {best_params}\")\n",
    "\n",
    "# 7. Train Final Model with Best Hyperparameters\n",
    "best_xgb = xgb.XGBRegressor(\n",
    "    **best_params,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 8. Model Evaluation\n",
    "y_val_pred_xgb = best_xgb.predict(X_val_scaled)\n",
    "val_mae_xgb = mean_absolute_error(y_val, y_val_pred_xgb)\n",
    "print(f\"Validation MAE (XGBoost) after tuning: {val_mae_xgb:.2f}\")\n",
    "\n",
    "\n",
    "# Cross-Validation (Use KFold for continuous target variable)\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores_xgb = cross_val_score(best_xgb, X_train_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error')\n",
    "mean_cv_score_xgb = -np.mean(cv_scores_xgb)\n",
    "print(f\"Mean Cross-Validation MAE (XGBoost): {mean_cv_score_xgb:.2f}\")\n",
    "\n",
    "\n",
    "# Calculate Validation Percentage Error for XGBoost\n",
    "val_percentage_error_xgb = np.mean(np.abs((y_val - y_val_pred_xgb) / y_val)) * 100\n",
    "print(f\"Validation Percentage Error (XGBoost): {val_percentage_error_xgb:.2f}%\")\n",
    "\n",
    "# 9. Predict on the test set and prepare submission\n",
    "test_predictions_xgb = best_xgb.predict(test_df_scaled)\n",
    "\n",
    "submission_df_xgb = submission_csv.copy()\n",
    "submission_df_xgb['TotalClaims'] = test_predictions_xgb\n",
    "\n",
    "submission_filename = 'final_submission_xgb_optimized_13.csv'\n",
    "submission_df_xgb.to_csv(submission_filename, index=False)\n",
    "print(f\"Submission file '{submission_filename}' created successfully!\")\n",
    "\n",
    "# Expected Output -\n",
    "# Validation MAE (XGBoost) after tuning: 421.35\n",
    "# Mean Cross-Validation MAE (XGBoost): 441.43\n",
    "# Validation Percentage Error (XGBoost): 1.21%\n",
    "# Submission file 'final_submission_xgb_optimized_13.csv' created successfully!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9461141,
     "sourceId": 84463,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
